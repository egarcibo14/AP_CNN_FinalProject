{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code was adapted from the following github: https://github.com/justjoshtings/satellite_image_segmentation"
      ],
      "metadata": {
        "id": "iTDVEb5sYBkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pystac pystac_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWO0LTaEYd7O",
        "outputId": "b63f17b3-c5d6-4246-acd5-6d02b9d0b101"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pystac\n",
            "  Downloading pystac-1.8.3-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pystac_client\n",
            "  Downloading pystac_client-0.7.2-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from pystac) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.28.2 in /usr/local/lib/python3.10/dist-packages (from pystac_client) (2.31.0)\n",
            "Requirement already satisfied: jsonschema<4.18,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from pystac) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->pystac) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.2->pystac_client) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.2->pystac_client) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.2->pystac_client) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.2->pystac_client) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.0.1->pystac) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.0.1->pystac) (0.19.3)\n",
            "Installing collected packages: pystac, pystac_client\n",
            "Successfully installed pystac-1.8.3 pystac_client-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup:\n",
        "\n",
        "Change the abspath_curr to reflect your drive/directories, which hase the data"
      ],
      "metadata": {
        "id": "WVWl4YTYY5XV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt_ZNcenX1x6",
        "outputId": "4e96b068-dc3c-48a3-cde4-25c7499e321a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the absolute path of the current folder\n",
        "abspath_curr = '/content/drive/My Drive/Application Development Final proj'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "import copy\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "\n",
        "import requests\n",
        "\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "import itertools as it\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "from pystac import Item\n",
        "from pystac.extensions.eo import EOExtension\n",
        "from pystac.extensions.label import LabelRelType\n",
        "from pystac.extensions.scientific import ScientificExtension\n",
        "from pystac_client import Client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ufGM5GYWQC",
        "outputId": "eac89bc1-eedd-4c30-bd66-696843c67e75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xVF878BKYJL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set matplotlib sizes\n",
        "plt.rc('font', size=20)\n",
        "plt.rc('axes', titlesize=20)\n",
        "plt.rc('axes', labelsize=20)\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('legend', fontsize=20)\n",
        "plt.rc('figure', titlesize=20)"
      ],
      "metadata": {
        "id": "6_--Bce6YkjJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Seed\n",
        "\n",
        "# The random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Set random seed in tensorflow\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# Set random seed in numpy\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "tPoIBcqWYlyX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what version of TF we are using\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoItqqS7YnmL",
        "outputId": "373c1ed9-3f8f-4e3d-c578-81d12cb53c69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of GPUs available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Test to see if GPU is found and connected\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('\\nFound GPU at: {}'.format(device_name))\n",
        "  print('\\nCurrently using:')\n",
        "  !nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZZOBfWfYpUd",
        "outputId": "631a3309-4c9c-4e6b-c879-e3b5416f050e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n",
            "GPU device not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List variable"
      ],
      "metadata": {
        "id": "NRRTErcQkCh5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4ghPR9ekCKx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TO-DO:\n",
        "\n",
        "Organize data based on Emma's directoires"
      ],
      "metadata": {
        "id": "wZaX8NxHYvDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Set Up Data Directories**\n",
        "\n",
        "The data is aviable for download in the following link:\n",
        "https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset?resource=download\n",
        "it is a litle bit heavy but the directories are already organized. It is necessary to make sure the directories of images and masks between **train**, **valid**, and **test** are setup correctly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EKuIIZ97oyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df = pd.read_csv(abspath_curr + \"/data/metadata.csv\")\n",
        "class_df = pd.read_csv(abspath_curr + \"/data/class_dict.csv\")\n",
        "\n",
        "print(class_df.head(10))\n",
        "\n",
        "print(meta_df.head())"
      ],
      "metadata": {
        "id": "GCOzd96AYrKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e938d4-f153-4b95-9828-96c23a7c6745"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               name    r    g    b\n",
            "0        urban_land    0  255  255\n",
            "1  agriculture_land  255  255    0\n",
            "2         rangeland  255    0  255\n",
            "3       forest_land    0  255    0\n",
            "4             water    0    0  255\n",
            "5       barren_land  255  255  255\n",
            "6           unknown    0    0    0\n",
            "   image_id  split        sat_image_path              mask_path\n",
            "0    100694  train  train/100694_sat.jpg  train/100694_mask.png\n",
            "1    102122  train  train/102122_sat.jpg  train/102122_mask.png\n",
            "2     10233  train   train/10233_sat.jpg   train/10233_mask.png\n",
            "3    103665  train  train/103665_sat.jpg  train/103665_mask.png\n",
            "4    103730  train  train/103730_sat.jpg  train/103730_mask.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Valid' does not have masks so let's merge that with the train and take a subset of train for validation\n",
        "meta_df[meta_df['split'] == 'valid'].head()"
      ],
      "metadata": {
        "id": "oP9xLdN2ZDGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3e5a5f5e-b081-44e1-c439-eb1f7471f6e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id  split        sat_image_path mask_path\n",
              "803    105036  valid  valid/105036_sat.jpg       NaN\n",
              "804    107780  valid  valid/107780_sat.jpg       NaN\n",
              "805    108490  valid  valid/108490_sat.jpg       NaN\n",
              "806    127801  valid  valid/127801_sat.jpg       NaN\n",
              "807    128240  valid  valid/128240_sat.jpg       NaN"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-52ba02ca-80e2-44fb-ba2e-34ea280e15da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>split</th>\n",
              "      <th>sat_image_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>105036</td>\n",
              "      <td>valid</td>\n",
              "      <td>valid/105036_sat.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>107780</td>\n",
              "      <td>valid</td>\n",
              "      <td>valid/107780_sat.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>108490</td>\n",
              "      <td>valid</td>\n",
              "      <td>valid/108490_sat.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>127801</td>\n",
              "      <td>valid</td>\n",
              "      <td>valid/127801_sat.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>128240</td>\n",
              "      <td>valid</td>\n",
              "      <td>valid/128240_sat.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52ba02ca-80e2-44fb-ba2e-34ea280e15da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0b52ca6d-8e5b-42bf-8032-49148541c088\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b52ca6d-8e5b-42bf-8032-49148541c088')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0b52ca6d-8e5b-42bf-8032-49148541c088 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52ba02ca-80e2-44fb-ba2e-34ea280e15da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52ba02ca-80e2-44fb-ba2e-34ea280e15da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update meta_df => with the actual path\n",
        "meta_df['sat_image_path'] = meta_df['sat_image_path'].str.replace('valid/', 'test/')\n",
        "meta_df['split'] = meta_df['split'].str.replace('valid', 'test')"
      ],
      "metadata": {
        "id": "NJ9DOf6MZEj0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can change the variable *0.9 for a one thet the user can change\n",
        "(Christina)"
      ],
      "metadata": {
        "id": "2padf8wyyL08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create divides for train, test, val\n",
        "train_df = meta_df[meta_df['split'] == 'train']\n",
        "\n",
        "#### Here we can change the variable *0.9 for a one that the user can change\n",
        "###########Christina\n",
        "train_num_samples = round(len(train_df)*0.75)\n",
        "val_num_samples = len(train_df) - train_num_samples"
      ],
      "metadata": {
        "id": "JtncSiZcZG4T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle all rows of DataFrame\n",
        "train_df = train_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "HaphDoMtZIUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "62933d61-86d4-46bc-926d-35dbebfe4789"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id  split                            sat_image_path  \\\n",
              "0    462612  train  train/train_images/images/462612_sat.jpg   \n",
              "1    935318  train  train/train_images/images/935318_sat.jpg   \n",
              "2     58910  train   train/train_images/images/58910_sat.jpg   \n",
              "3    471187  train  train/train_images/images/471187_sat.jpg   \n",
              "4    548686  train  train/train_images/images/548686_sat.jpg   \n",
              "\n",
              "                                 mask_path  \n",
              "0  train/train_masks/masks/462612_mask.png  \n",
              "1  train/train_masks/masks/935318_mask.png  \n",
              "2   train/train_masks/masks/58910_mask.png  \n",
              "3  train/train_masks/masks/471187_mask.png  \n",
              "4  train/train_masks/masks/548686_mask.png  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e9006378-274c-4816-a552-af4c6080b147\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>split</th>\n",
              "      <th>sat_image_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462612</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/462612_sat.jpg</td>\n",
              "      <td>train/train_masks/masks/462612_mask.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>935318</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/935318_sat.jpg</td>\n",
              "      <td>train/train_masks/masks/935318_mask.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58910</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/58910_sat.jpg</td>\n",
              "      <td>train/train_masks/masks/58910_mask.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>471187</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/471187_sat.jpg</td>\n",
              "      <td>train/train_masks/masks/471187_mask.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>548686</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/548686_sat.jpg</td>\n",
              "      <td>train/train_masks/masks/548686_mask.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9006378-274c-4816-a552-af4c6080b147')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1817cec6-fb19-47fe-80ad-c3f579b85640\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1817cec6-fb19-47fe-80ad-c3f579b85640')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1817cec6-fb19-47fe-80ad-c3f579b85640 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9006378-274c-4816-a552-af4c6080b147 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9006378-274c-4816-a552-af4c6080b147');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "these two lines of code split the shuffled training dataset into a training portion and a validation portion by updating the 'split' column values accordingly. The first train_num_samples rows are marked as 'train', and the remaining rows are marked as 'valid'."
      ],
      "metadata": {
        "id": "kujX9r2d5rV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['split'].iloc[:train_num_samples] = 'train'\n",
        "train_df['split'].iloc[train_num_samples:] = 'valid'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSxw4ARy5Xcl",
        "outputId": "dc60c7c7-2cff-4fe3-f5da-08d0c931b4c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b71c466edf33>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'].iloc[:train_num_samples] = 'train'\n",
            "<ipython-input-22-b71c466edf33>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'].iloc[train_num_samples:] = 'valid'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_train_df = meta_df[meta_df['split'] != 'train']\n",
        "\n",
        "train_df['sat_image_path'] = train_df['sat_image_path'].str.replace('train/', 'train/train_images/images/')\n",
        "train_df['mask_path'] = train_df['mask_path'].str.replace('train/', 'train/train_masks/masks/')\n",
        "\n",
        "meta_df = pd.concat([train_df, non_train_df], axis=0)\n",
        "meta_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "1zyOUqo86RZl",
        "outputId": "45e74041-c9bc-4fe1-abd1-41368db2523e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id  split                                     sat_image_path  \\\n",
              "0    462612  train  train/train_images/images/train_images/images/...   \n",
              "1    935318  train  train/train_images/images/train_images/images/...   \n",
              "2     58910  train  train/train_images/images/train_images/images/...   \n",
              "3    471187  train  train/train_images/images/train_images/images/...   \n",
              "4    548686  train  train/train_images/images/train_images/images/...   \n",
              "\n",
              "                                           mask_path  \n",
              "0  train/train_masks/masks/train_masks/masks/4626...  \n",
              "1  train/train_masks/masks/train_masks/masks/9353...  \n",
              "2  train/train_masks/masks/train_masks/masks/5891...  \n",
              "3  train/train_masks/masks/train_masks/masks/4711...  \n",
              "4  train/train_masks/masks/train_masks/masks/5486...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4284a99b-38cd-48f5-9778-e85ccb75139f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>split</th>\n",
              "      <th>sat_image_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462612</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/4626...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>935318</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/9353...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58910</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/5891...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>471187</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/4711...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>548686</td>\n",
              "      <td>train</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/5486...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4284a99b-38cd-48f5-9778-e85ccb75139f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b23eadd6-60f4-4423-bc48-e9bc12c5aa55\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b23eadd6-60f4-4423-bc48-e9bc12c5aa55')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b23eadd6-60f4-4423-bc48-e9bc12c5aa55 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4284a99b-38cd-48f5-9778-e85ccb75139f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4284a99b-38cd-48f5-9778-e85ccb75139f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have labeled validation data to work with.\n",
        "\n",
        "The code snippet is extracting and displaying the initial rows of the DataFrame meta_df that correspond to the validation split,"
      ],
      "metadata": {
        "id": "mjdY6D1876HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df[meta_df['split'] == 'valid'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "U_AV57JF75Yt",
        "outputId": "52a05c52-28ef-4104-fa9c-ad4211ce55ea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id  split                                     sat_image_path  \\\n",
              "542    499266  valid  train/train_images/images/train_images/images/...   \n",
              "543    748225  valid  train/train_images/images/train_images/images/...   \n",
              "544    291214  valid  train/train_images/images/train_images/images/...   \n",
              "545    129298  valid  train/train_images/images/train_images/images/...   \n",
              "546    137499  valid  train/train_images/images/train_images/images/...   \n",
              "\n",
              "                                             mask_path  \n",
              "542  train/train_masks/masks/train_masks/masks/4992...  \n",
              "543  train/train_masks/masks/train_masks/masks/7482...  \n",
              "544  train/train_masks/masks/train_masks/masks/2912...  \n",
              "545  train/train_masks/masks/train_masks/masks/1292...  \n",
              "546  train/train_masks/masks/train_masks/masks/1374...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3cf8dc26-dd65-4dbf-9ad6-2e28a824ea5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>split</th>\n",
              "      <th>sat_image_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>499266</td>\n",
              "      <td>valid</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/4992...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>748225</td>\n",
              "      <td>valid</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/7482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>291214</td>\n",
              "      <td>valid</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/2912...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>129298</td>\n",
              "      <td>valid</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/1292...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>137499</td>\n",
              "      <td>valid</td>\n",
              "      <td>train/train_images/images/train_images/images/...</td>\n",
              "      <td>train/train_masks/masks/train_masks/masks/1374...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cf8dc26-dd65-4dbf-9ad6-2e28a824ea5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-32aa9045-0c2d-4fc7-b5fe-6f0d7e0606df\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32aa9045-0c2d-4fc7-b5fe-6f0d7e0606df')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-32aa9045-0c2d-4fc7-b5fe-6f0d7e0606df button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cf8dc26-dd65-4dbf-9ad6-2e28a824ea5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cf8dc26-dd65-4dbf-9ad6-2e28a824ea5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final dataset split redy to process will be this:"
      ],
      "metadata": {
        "id": "7YiaKiz-9Ni2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Samples in train: ', len(meta_df[meta_df['split'] == 'train']))\n",
        "print('Samples in validation: ', len(meta_df[meta_df['split'] == 'valid']))\n",
        "print('Samples in test: ', len(meta_df[meta_df['split'] == 'test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ8vFQM38vK9",
        "outputId": "c7f7f2f3-c5ab-4e3b-a88c-243def3aa2b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples in train:  542\n",
            "Samples in validation:  261\n",
            "Samples in test:  343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The levels have the following values\n",
        "This is what our classes look like."
      ],
      "metadata": {
        "id": "B0-euY7o9mUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_df = pd.read_csv(abspath_curr + \"/data/class_dict.csv\")\n",
        "\n",
        "class_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tjVeKMLZELvd",
        "outputId": "c70b1a6a-355d-4833-aa74-0babb501decd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               name    r    g    b\n",
              "0        urban_land    0  255  255\n",
              "1  agriculture_land  255  255    0\n",
              "2         rangeland  255    0  255\n",
              "3       forest_land    0  255    0\n",
              "4             water    0    0  255\n",
              "5       barren_land  255  255  255\n",
              "6           unknown    0    0    0"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-83c1d8e5-4ce7-4641-8fa8-5d2e1605c18f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>r</th>\n",
              "      <th>g</th>\n",
              "      <th>b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>urban_land</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>agriculture_land</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rangeland</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>forest_land</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>water</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>barren_land</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83c1d8e5-4ce7-4641-8fa8-5d2e1605c18f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-88daa255-5f19-4adf-aff0-33da085f742f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88daa255-5f19-4adf-aff0-33da085f742f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-88daa255-5f19-4adf-aff0-33da085f742f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83c1d8e5-4ce7-4641-8fa8-5d2e1605c18f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83c1d8e5-4ce7-4641-8fa8-5d2e1605c18f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Move Files**\n",
        "\n",
        "Move images to their correct directories based on train, validation, and testing splits."
      ],
      "metadata": {
        "id": "R9n6NJ30EcDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_directory(path):\n",
        "  \"\"\"\n",
        "  Function to make directory if not exits\n",
        "\n",
        "  Paramater:\n",
        "    path - path of directory\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  directory = os.path.dirname(path)\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "  return\n"
      ],
      "metadata": {
        "id": "Cjh3nt0lEMO2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make directories => inside the directories allready have\n",
        "make_directory(abspath_curr + '/data/train/train_images/images/')\n",
        "make_directory(abspath_curr + '/data/train/train_masks/masks/')\n",
        "\n",
        "make_directory(abspath_curr + '/data/val/val_images/images/')\n",
        "make_directory(abspath_curr + '/data/val/val_masks/masks/')"
      ],
      "metadata": {
        "id": "OIug-iZaEfje"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HteejJ7ElDlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_files(list_filenames, source_path, target_path):\n",
        "  \"\"\"\n",
        "  Function to move files from source to target directory based on a list of filenames within source\n",
        "\n",
        "  Parameters:\n",
        "    list_filesname - list of filenames\n",
        "    source_path - path of source directory\n",
        "    target_path - path of target directory\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for file_name in list_filenames:\n",
        "      try:\n",
        "        shutil.move(os.path.join(source_path, file_name), os.path.join(target_path, file_name))\n",
        "      except FileNotFoundError:\n",
        "        continue"
      ],
      "metadata": {
        "id": "8aTwMQEBEfaG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of test, val filenames =>  variables to copy in the other folders crated\n",
        "\n",
        "train_sat_img_path = meta_df[meta_df['split'] == 'train']['sat_image_path']\n",
        "\n",
        "train_sat_img_path = train_sat_img_path.str.replace('train/train_images/images/', '')\n",
        "\n",
        "\n",
        "\n",
        "new_val_sat_img_path = meta_df[meta_df['split'] == 'valid']['sat_image_path']\n",
        "\n",
        "new_val_sat_img_path = new_val_sat_img_path.str.replace('val/val_images/images/', '')\n",
        "\n",
        "\n",
        "\n",
        "train_msk_img_path = meta_df[meta_df['split'] == 'train']['mask_path']\n",
        "\n",
        "train_msk_img_path = train_msk_img_path.str.replace('train/train_masks/masks/', '')\n",
        "\n",
        "\n",
        "\n",
        "new_val_msk_img_path = meta_df[meta_df['split'] == 'valid']['mask_path']\n",
        "\n",
        "new_val_msk_img_path = new_val_msk_img_path.str.replace('val/val_masks/masks/', '')\n",
        "\n",
        "\n",
        "\n",
        "old_val_img_path = os.listdir(abspath_curr + '/data/valid/')\n",
        "\n",
        "#té un menú contextual"
      ],
      "metadata": {
        "id": "ZBoyl1KVlE-p"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines a function named folder_is_empty that checks whether a given folder (path) contains certain image files. The function can be used to determine if a folder is \"empty\" based on the presence of specific image file types."
      ],
      "metadata": {
        "id": "m6U9F6fFm4FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def folder_is_empty(path, img_types=['.png', '.jpg', '.tif']):\n",
        "  \"\"\"\n",
        "  Function to check if a filepath is empty\n",
        "\n",
        "  Parameters:\n",
        "    path - filepath to image or mask data\n",
        "\n",
        "  Return:\n",
        "    True if empty, False if not\n",
        "\n",
        "  We can use this function like this:\n",
        "    if not False:\n",
        "      do X\n",
        "    else:\n",
        "      do Y\n",
        "\n",
        "  this will do X.\n",
        "  \"\"\"\n",
        "\n",
        "  if any(list(map(lambda x: True if x in ''.join(os.listdir(path)) else False, img_types))):\n",
        "    return False\n",
        "  else:\n",
        "    return True"
      ],
      "metadata": {
        "id": "5sgwBSeDEuE2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moves files from main folders of train, val to sub-directories\n",
        "\n",
        "# Old validation goes to test\n",
        "if not folder_is_empty(abspath_curr + '/data/valid'):\n",
        "  # image\n",
        "  move_files(old_val_img_path, abspath_curr + '/data/valid/', abspath_curr + '/data/test')\n",
        "\n",
        "# Split old train to new train and new val\n",
        "if not folder_is_empty(abspath_curr + '/data/train'):\n",
        "  # train_image\n",
        "  move_files(train_sat_img_path, abspath_curr + '/data/train/', abspath_curr + '/data/train/train_images/images')\n",
        "  # train_mask\n",
        "  move_files(train_msk_img_path, abspath_curr + '/data/train/', abspath_curr + '/data/train/train_masks/masks')\n",
        "\n",
        "  # val_image\n",
        "  move_files(new_val_sat_img_path, abspath_curr + '/data/train/', abspath_curr + '/data/val/val_images/images')\n",
        "  # val_mask\n",
        "  move_files(new_val_msk_img_path, abspath_curr + '/data/train/', abspath_curr + '/data/val/val_masks/masks')\n",
        "\n"
      ],
      "metadata": {
        "id": "wtd-x4eKRgNH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if images got moved right\n",
        "print('Train Images: ', len(os.listdir(abspath_curr + '/data/train/train_images/images')))\n",
        "print('Train Masks: ',len(os.listdir(abspath_curr + '/data/train/train_masks/masks')))\n",
        "\n",
        "print('Val Images: ',len(os.listdir(abspath_curr + '/data/val/val_images/images')))\n",
        "print('Val Masks: ',len(os.listdir(abspath_curr + '/data/val/val_masks/masks')))\n",
        "\n",
        "print('Test Images: ',len(os.listdir(abspath_curr + '/data/test')))\n",
        "print('Test Masks: ',len(os.listdir(abspath_curr + '/data/test')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcOF1z1FnSZp",
        "outputId": "a8d3a436-46d1-4e1a-b97b-e2d7a7c1d826"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images:  0\n",
            "Train Masks:  0\n",
            "Val Images:  0\n",
            "Val Masks:  0\n",
            "Test Images:  175\n",
            "Test Masks:  175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Convert masks to .png to prevent loss and generally preferred over .jpg**\n",
        "\n",
        "Masks are generally preferred to be in .png format. We convert to .png if the masks were not already in .png format."
      ],
      "metadata": {
        "id": "LB9sx3henV0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_file_type(filepath, dest_file_type):\n",
        "  \"\"\"\n",
        "  Function to convert all files in a directory to a defined file type\n",
        "\n",
        "  Parameters:\n",
        "    filepath - filepath\n",
        "    dest_file_type - str of dest_file_type ('.png')\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for mask_file in os.listdir(filepath):\n",
        "    try:\n",
        "        # Attempt to open an image file\n",
        "        image = cv2.imread(filepath + '/' + mask_file)\n",
        "    except IOError as e:\n",
        "        # Report error, and then skip to the next argument\n",
        "        print (\"Problem opening\", mask_file, \":\", e)\n",
        "        continue\n",
        "\n",
        "    # Split our original filename into name and extension\n",
        "    (name, extension) = os.path.splitext(mask_file)\n",
        "\n",
        "    # Save new file type\n",
        "    cv2.imwrite(filepath + '/' + name + dest_file_type, image)\n",
        "\n",
        "    # Delete original copy\n",
        "    os.remove(filepath + '/' + mask_file)"
      ],
      "metadata": {
        "id": "sYrmgKBWngJK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If .jpg or .tif found in masks directories, convert them into .png type\n",
        "\n",
        "if not folder_is_empty(abspath_curr + '/data/train/train_masks/masks', img_types=['.jpg', '.tif']):\n",
        "  convert_file_type(abspath_curr + '/data/train/train_masks/masks', '.png')\n",
        "\n",
        "if not folder_is_empty(abspath_curr + '/data/val/val_masks/masks', img_types=['.jpg', '.tif']):\n",
        "  convert_file_type(abspath_curr + '/data/val/val_masks/masks', '.png')"
      ],
      "metadata": {
        "id": "j9MaHkpGn0x5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cut up images to have more samples and smaller training features**\n",
        "\n",
        "Since the original images are 2448x2448x3, it requires a lot of computing resources to be loaded at a time to train just one image. Instead, we can cut up the images into smaller patches to reduce the amount of computing resources needed to load one image into memory and train."
      ],
      "metadata": {
        "id": "J-sLQYSxn79h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_images(filepath, dest_filepath, n_sub_images):\n",
        "  \"\"\"\n",
        "  Function to convert all masks to only forest labeled masks\n",
        "\n",
        "  Parameters:\n",
        "    filepath - source filepath\n",
        "    dest_filepath - destination filepath\n",
        "    n_sub_images - number of images to cut\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for mask_file in os.listdir(filepath):\n",
        "    try:\n",
        "        # Attempt to open an image file\n",
        "        image = plt.imread(filepath + '/' + mask_file)\n",
        "    except IOError as e:\n",
        "        # Report error, and then skip to the next argument\n",
        "        print (\"Problem opening\", mask_file, \":\", e)\n",
        "        continue\n",
        "\n",
        "    pixels = int(image.shape[0] / math.sqrt(n_sub_images))\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for r in range(0,image.shape[0],pixels):\n",
        "      for c in range(0,image.shape[1],pixels):\n",
        "\n",
        "        filename = mask_file.split('.')[0]\n",
        "        extension = mask_file.split('.')[1]\n",
        "\n",
        "        # Save new file type\n",
        "        plt.imsave(dest_filepath + filename + '_{}.'.format(count) + extension, image[r:r+pixels, c:c+pixels,:])\n",
        "\n",
        "        count+=1\n",
        "\n",
        "    os.remove(filepath + '/' + mask_file)\n",
        "  print('Images of: {}x{}'.format(pixels, pixels))"
      ],
      "metadata": {
        "id": "GMJZbN8Gn6_R"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_cut_images = False\n",
        "\n",
        "if run_cut_images:\n",
        "  # Images\n",
        "  cut_images(abspath_curr + '/data/train/train_images/images/', abspath_curr + '/data/train/train_images/images/', 16)\n",
        "  cut_images(abspath_curr + '/data/val/val_images/images/', abspath_curr + '/data/val/val_images/images/', 16)\n",
        "  cut_images(abspath_curr + '/data/test/', abspath_curr + '/data/test/', 16)\n",
        "\n",
        "  # Masks\n",
        "  cut_images(abspath_curr + '/data/train/train_masks/masks/', abspath_curr + '/data/train/train_masks/masks/', 16)\n",
        "  cut_images(abspath_curr + '/data/val/val_masks/masks/', abspath_curr + '/data/val/val_masks/masks/', 16)"
      ],
      "metadata": {
        "id": "5r0ksnxApic6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if images got moved right\n",
        "print('Train Images: ', len(os.listdir(abspath_curr + '/data/train/train_images/images')))\n",
        "print('Train Masks: ',len(os.listdir(abspath_curr + '/data/train/train_masks/masks')))\n",
        "\n",
        "print('Val Images: ',len(os.listdir(abspath_curr + '/data/val/val_images/images')))\n",
        "print('Val Masks: ',len(os.listdir(abspath_curr + '/data/val/val_masks/masks')))\n",
        "\n",
        "print('Test Images: ',len(os.listdir(abspath_curr + '/data/test')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPjhaTXhpu34",
        "outputId": "eb4664b6-5f69-426c-f844-3ed6cf09d161"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images:  0\n",
            "Train Masks:  0\n",
            "Val Images:  0\n",
            "Val Masks:  0\n",
            "Test Images:  175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Class Weights**\n",
        "\n",
        "Let's take a look at the class imbalance/balance. We will look at the number of pixels that belongs to each class."
      ],
      "metadata": {
        "id": "06bV3LQxp7GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pixels_class_weights(path, class_map):\n",
        "  \"\"\"\n",
        "  Function to go to specified mask path, go through each image\n",
        "  and count number of pixels that belong to each class\n",
        "\n",
        "  Parameters:\n",
        "    paths: path to images\n",
        "    class_map: class_df\n",
        "\n",
        "  Return:\n",
        "    pixel_counts: np array of pixel counts in order of class appearance in class_df\n",
        "  \"\"\"\n",
        "  images = os.listdir(path)\n",
        "\n",
        "  pixel_counts = np.zeros(len(class_map))\n",
        "\n",
        "  # Iterate through image\n",
        "  for image in images:\n",
        "    img = plt.imread(path+image)\n",
        "\n",
        "    # Iterate through class_map\n",
        "    class_counter = 0\n",
        "    for index, row in class_df.iterrows():\n",
        "        new_img = copy.deepcopy(img[::,::,::])\n",
        "\n",
        "        R = new_img[::,::,0]\n",
        "        G = new_img[::,::,1]\n",
        "        B = new_img[::,::,2]\n",
        "\n",
        "        #method to check where rgb = 0, 255, 255 etc, subset it & np.count_nonzero\n",
        "        count = (new_img[(R == row['r']/255) & (G == row['g']/255) & (B == row['b']/255)].size)/3\n",
        "\n",
        "        # add count to array\n",
        "        pixel_counts[class_counter]+=count\n",
        "\n",
        "        class_counter+=1\n",
        "\n",
        "  return pixel_counts\n",
        "\n",
        "def pixels_class_weights(paths_list, save_path, class_map=None):\n",
        "  \"\"\"\n",
        "  Function to get pixels class weights for classes\n",
        "\n",
        "  Parameters:\n",
        "    paths_list: list of paths\n",
        "    class_map: class_df\n",
        "\n",
        "  Return:\n",
        "    class_pixels: pandas df of classes and percentage of pixels belonging to that class\n",
        "  \"\"\"\n",
        "  class_pixels = class_map.copy()\n",
        "  class_pixels['Pixels_Count'] = 0\n",
        "\n",
        "  for counter, path in enumerate(paths_list):\n",
        "    pixels_count_array = get_pixels_class_weights(path, class_map)\n",
        "    # hstack each array to df, sum columns and drop stacked column\n",
        "    class_pixels['Pixels_Count_{}'.format(counter)] = pixels_count_array.tolist()\n",
        "    class_pixels['Pixels_Count'] = class_pixels['Pixels_Count'] + class_pixels['Pixels_Count_{}'.format(counter)]\n",
        "    # drop rgb cols in df\n",
        "    class_pixels.drop('Pixels_Count_{}'.format(counter), axis=1, inplace=True)\n",
        "\n",
        "  # Percentage of pixels in each class\n",
        "  class_pixels['Weights'] = round(class_pixels['Pixels_Count']/class_pixels['Pixels_Count'].sum(), 2)\n",
        "\n",
        "  # Weighting to use for calculating loss\n",
        "  class_pixels['True Weights'] = (1 / class_pixels['Pixels_Count']) * class_pixels['Pixels_Count'].sum()/class_pixels.shape[0]\n",
        "  class_pixels.loc[6,'True Weights'] = 0.001\n",
        "\n",
        "  # Save results\n",
        "  make_directory(save_path)\n",
        "  class_pixels.to_csv(save_path+'class_pixels_count.csv', index=False)\n",
        "\n",
        "  return class_pixels\n"
      ],
      "metadata": {
        "id": "2wBAg3jZp6jR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the number and percentage of pixels that belong to each class. Note that the highest is the agriculture class where 58% of the pixels belong to this class. We will see how this affects our model's performance."
      ],
      "metadata": {
        "id": "SQi0hW4SqG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_pixels = False\n",
        "\n",
        "if run_class_pixels:\n",
        "  class_pixels = pixels_class_weights([abspath_curr + '/data/train/train_masks/masks/', ],\n",
        "                                      abspath_curr + '/result/class_distribution/',\n",
        "                                      class_map=class_df)\n",
        "\n",
        "else:\n",
        "  class_pixels = pd.read_csv(abspath_curr + '/result/class_distribution/class_pixels_count.csv')\n",
        "\n",
        "print(class_pixels.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "F25JCIJYqH-C",
        "outputId": "31f01382-613e-491d-e16f-e18a1b5ff672"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-6bd297608868>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mclass_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabspath_curr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/result/class_distribution/class_pixels_count.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_pixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Application Development Final proj/result/class_distribution/class_pixels_count.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Data**"
      ],
      "metadata": {
        "id": "jL24VIgaqo55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sanity Check**"
      ],
      "metadata": {
        "id": "ysnevR1FqttB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check, view few mages\n",
        "def peek_images(sample_images, sample_masks=None, encode=None, color_scale=None, file_name=None, mask_name=None, predict=None, model=None, sample_images2=None, model_alt=None):\n",
        "  \"\"\"\n",
        "  Function to plot a randomly selected training set (or validation set if given validation filepaths)\n",
        "\n",
        "  Parameters:\n",
        "    sample_images: image in np array\n",
        "    sample_masks: mask in np array\n",
        "    encode: Boolean to set encoding type 'uint8' or not\n",
        "    color_scale: set to 'gray' to set grayscale\n",
        "    file_name: filename to display in image plot tile\n",
        "    mask_name: filename to display in mask plot tile\n",
        "    predict: Boolean, set to True if want to show prediction plots\n",
        "    model: instance of Keras model object to use .predict() on\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  image_number = random.randint(0, sample_images.shape[0]-1)\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Original Image\n",
        "  if predict is not None and model is not None and model_alt is not None:\n",
        "    plt.subplot(141)\n",
        "  elif predict is not None and model is not None and model_alt is None:\n",
        "    plt.subplot(131)\n",
        "  else:\n",
        "    plt.subplot(121)\n",
        "\n",
        "  if encode == 'uint8':\n",
        "    plt.imshow(sample_images.astype(('uint8')))\n",
        "  else:\n",
        "    plt.imshow(sample_images)\n",
        "  plt.title('Original:\\n{}'.format(file_name), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Mask\n",
        "  if predict is not None and model is not None and model_alt is not None:\n",
        "    plt.subplot(142)\n",
        "  elif predict is not None and model is not None and model_alt is None:\n",
        "    plt.subplot(132)\n",
        "  else:\n",
        "    plt.subplot(122)\n",
        "\n",
        "  if encode == 'uint8':\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(sample_masks.astype(('uint8')), cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(sample_masks.astype(('uint8')))\n",
        "  else:\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(sample_masks, cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(sample_masks)\n",
        "  plt.title('Ground Truth Mask:\\n{}'.format(mask_name), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  if predict is not None and model is not None and model_alt is not None:\n",
        "    plt.subplot(143)\n",
        "  if predict is not None and model is not None and model_alt is None:\n",
        "    plt.subplot(133)\n",
        "    # Prediction\n",
        "\n",
        "  if predict is not None:\n",
        "    # Turn (612, 612, 3) to (1, 612, 612, 3)\n",
        "    if len(sample_images.shape) == 3:\n",
        "      sample_images = np.expand_dims(sample_images, axis=0)\n",
        "\n",
        "    # Predict image\n",
        "    predicted_image = model.predict(sample_images)\n",
        "    predicted_image = predicted_image[0,::,::,::]\n",
        "    # Reverse one hot encode predicted mask\n",
        "    predicted_image_decoded = reverse_one_hot_encode(predicted_image)\n",
        "\n",
        "\n",
        "    if encode == 'uint8':\n",
        "      if color_scale == 'gray':\n",
        "        plt.imshow(predicted_image_decoded.astype(('uint8')), cmap='gray')\n",
        "      else:\n",
        "        plt.imshow(predicted_image_decoded.astype(('uint8')))\n",
        "    else:\n",
        "      if color_scale == 'gray':\n",
        "        plt.imshow(predicted_image_decoded, cmap='gray')\n",
        "      else:\n",
        "        plt.imshow(predicted_image_decoded)\n",
        "    plt.title('Predicted Mask {}:'.format(model.name), fontdict = {'fontsize' : 8})\n",
        "    plt.axis('off')\n",
        "\n",
        "  if predict is not None and model is not None and model_alt is not None:\n",
        "    # Prediction #2\n",
        "\n",
        "    # Turn (612, 612, 3) to (1, 612, 612, 3)\n",
        "    if len(sample_images2.shape) == 3:\n",
        "      sample_images2 = np.expand_dims(sample_images2, axis=0)\n",
        "\n",
        "    # Predict image\n",
        "    predicted_image = model_alt.predict(sample_images2)\n",
        "    predicted_image = predicted_image[0,::,::,::]\n",
        "    # Reverse one hot encode predicted mask\n",
        "    predicted_image_decoded = reverse_one_hot_encode(predicted_image)\n",
        "\n",
        "    plt.subplot(144)\n",
        "    if encode == 'uint8':\n",
        "      if color_scale == 'gray':\n",
        "        plt.imshow(predicted_image_decoded.astype(('uint8')), cmap='gray')\n",
        "      else:\n",
        "        plt.imshow(predicted_image_decoded.astype(('uint8')))\n",
        "    else:\n",
        "      if color_scale == 'gray':\n",
        "        plt.imshow(predicted_image_decoded, cmap='gray')\n",
        "      else:\n",
        "        plt.imshow(predicted_image_decoded)\n",
        "    plt.title('Predicted Mask {}:'.format(model_alt.name), fontdict = {'fontsize' : 8})\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "PVphqVQNq1c6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def peek_masks_breakdown(sample_images, sample_masks=None, encode=None, color_scale=None, file_name=None, mask_name=None, predict=None, model=None):\n",
        "  \"\"\"\n",
        "  Function to plot a randomly selected prediction mask and breakdown channels\n",
        "\n",
        "  Parameters:\n",
        "    sample_images: image in np array\n",
        "    sample_masks: mask in np array\n",
        "    encode: Boolean to set encoding type 'uint8' or not\n",
        "    color_scale: set to 'gray' to set grayscale\n",
        "    file_name: filename to display in image plot tile\n",
        "    mask_name: filename to display in mask plot tile\n",
        "    predict: Boolean, set to True if want to show prediction plots\n",
        "    model: instance of Keras model object to use .predict() on\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  image_number = random.randint(0, sample_images.shape[0]-1)\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Turn (612, 612, 3) to (1, 612, 612, 3)\n",
        "  if len(sample_images.shape) == 3:\n",
        "    sample_images = np.expand_dims(sample_images, axis=0)\n",
        "\n",
        "  # Predict image\n",
        "  predicted_image = model.predict(sample_images)\n",
        "  predicted_image = predicted_image[0,::,::,::]\n",
        "  predicted_image = rescale(predicted_image)\n",
        "\n",
        "  # Reverse one hot encode predicted mask\n",
        "  predicted_image_decoded = reverse_one_hot_encode(predicted_image)\n",
        "  predicted_image_decoded = rescale(predicted_image_decoded)\n",
        "\n",
        "  # Predicted\n",
        "  plt.subplot(4,2,1)\n",
        "\n",
        "  if encode == 'uint8':\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(predicted_image_decoded.astype(('uint8')), cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(predicted_image_decoded.astype(('uint8')))\n",
        "  else:\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(predicted_image_decoded, cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(predicted_image_decoded)\n",
        "  plt.title('Predicted Mask {}:'.format(model.name), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  labels = ['Urban Land, Light Blue:',\n",
        "            'Agriculture Land, Yellow:',\n",
        "            'Rangeland, Purple:',\n",
        "            'Forest Land, Green:',\n",
        "            'Water, Blue:',\n",
        "            'Barren Land, White:',\n",
        "            'Unknown, Black:'\n",
        "            ]\n",
        "\n",
        "  all_colored_channel_activations = 0\n",
        "\n",
        "  for i in range(predicted_image.shape[-1]-1):\n",
        "    # Channels\n",
        "    plt.subplot(4,2,i+2)\n",
        "    plt.imshow(predicted_image[::,::,i])\n",
        "\n",
        "    pixels_activated = np.count_nonzero(predicted_image[::,::,i] >= 1)\n",
        "    percent_pixels_activated = round(pixels_activated / np.size(predicted_image[::,::,i]) * 100, 5)\n",
        "\n",
        "    all_colored_channel_activations+=percent_pixels_activated\n",
        "\n",
        "    plt.title(labels[i] + '{}% Pixels Activated'.format(percent_pixels_activated), fontdict = {'fontsize' : 8})\n",
        "    plt.axis('off')\n",
        "\n",
        "  # Unknown Channel\n",
        "  plt.subplot(4,2,8)\n",
        "  plt.imshow(predicted_image[::,::,6])\n",
        "\n",
        "  plt.title(labels[-1] + '{}% Pixels Activated'.format(round(100 - all_colored_channel_activations, 5)), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "1kH6yJW4rAiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check, view few mages\n",
        "def peek_images_test(sample_images, sample_masks=None, encode=None, color_scale=None, file_name=None, mask_name=None, predict=None, model=None):\n",
        "  \"\"\"\n",
        "  Function to plot a randomly selected testing set\n",
        "\n",
        "  Parameters:\n",
        "    sample_images: image in np array\n",
        "    sample_masks: mask in np array\n",
        "    encode: Boolean to set encoding type 'uint8' or not\n",
        "    color_scale: set to 'gray' to set grayscale\n",
        "    file_name: filename to display in image plot tile\n",
        "    mask_name: filename to display in mask plot tile\n",
        "    predict: Boolean, set to True if want to show prediction plots\n",
        "    model: instance of Keras model object to use .predict() on\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  image_number = random.randint(0, sample_images.shape[0]-1)\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Original Image\n",
        "  plt.subplot(121)\n",
        "\n",
        "  if encode == 'uint8':\n",
        "    plt.imshow(sample_images.astype(('uint8')))\n",
        "  else:\n",
        "    plt.imshow(sample_images)\n",
        "  plt.title('Original:\\n{}'.format(file_name), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Prediction\n",
        "  plt.subplot(122)\n",
        "\n",
        "  # Turn (612, 612, 3) to (1, 612, 612, 3)\n",
        "  if len(sample_images.shape) == 3:\n",
        "    sample_images = np.expand_dims(sample_images, axis=0)\n",
        "\n",
        "  # Predict image\n",
        "  predicted_image = model.predict(sample_images)\n",
        "  predicted_image = predicted_image[0,::,::,::]\n",
        "  # Reverse one hot encode predicted mask\n",
        "  predicted_image_decoded = reverse_one_hot_encode(predicted_image)\n",
        "\n",
        "  if encode == 'uint8':\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(predicted_image_decoded.astype(('uint8')), cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(predicted_image_decoded.astype(('uint8')))\n",
        "  else:\n",
        "    if color_scale == 'gray':\n",
        "      plt.imshow(predicted_image_decoded, cmap='gray')\n",
        "    else:\n",
        "      plt.imshow(predicted_image_decoded)\n",
        "  plt.title('Predicted Mask {}:'.format(model.name), fontdict = {'fontsize' : 8})\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "LOBJuilIrGJK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_check(sample_images, sample_masks=None, encode=None, color_scale=None, predict=None, model=None, model_alt=None, predicted_breakdown=None, imsize=None, imsize_alt=None):\n",
        "  \"\"\"\n",
        "  Function to get a training set (or validation set if given validation filepaths) and calls plotting functions\n",
        "\n",
        "  Parameters:\n",
        "    sample_images: image in np array\n",
        "    sample_masks: mask in np array\n",
        "    encode: Boolean to set encoding type 'uint8' or not\n",
        "    color_scale: set to 'gray' to set grayscale\n",
        "    file_name: filename to display in image plot tile\n",
        "    mask_name: filename to display in mask plot tile\n",
        "    predict: Boolean, set to True if want to show prediction plots\n",
        "    model: instance of Keras model object to use .predict() on\n",
        "\n",
        "  Return:\n",
        "    None\n",
        "  \"\"\"\n",
        "  image_number = random.randint(0, len(os.listdir(sample_images))-1)\n",
        "\n",
        "  file_name = sorted(os.listdir(sample_images))[image_number]\n",
        "  image_file = sorted(os.listdir(sample_images))[image_number]\n",
        "  image = np.array(plt.imread(sample_images + image_file))\n",
        "\n",
        "  if sample_masks is not None:\n",
        "    mask_name = sorted(os.listdir(sample_masks))[image_number]\n",
        "    mask_file = sorted(os.listdir(sample_masks))[image_number]\n",
        "    mask = np.array(plt.imread(sample_masks + mask_file))\n",
        "\n",
        "  if imsize is not None and sample_masks is not None:\n",
        "    image =  cv2.resize(image, (imsize, imsize))\n",
        "    mask =  cv2.resize(mask, (imsize, imsize))\n",
        "  elif imsize is not None and sample_masks is None:\n",
        "    image =  cv2.resize(image, (imsize, imsize))\n",
        "\n",
        "  image1 = copy.deepcopy(image)\n",
        "\n",
        "  if model_alt:\n",
        "    image2 = copy.deepcopy(image)\n",
        "    if imsize_alt is not None and sample_masks is not None:\n",
        "      image2 =  cv2.resize(image, (imsize_alt, imsize_alt))\n",
        "      mask =  cv2.resize(mask, (imsize_alt, imsize_alt))\n",
        "    elif imsize_alt is not None and sample_masks is None:\n",
        "      image2 =  cv2.resize(image, (imsize_alt, imsize_alt))\n",
        "  else:\n",
        "    image2 = None\n",
        "\n",
        "  # Compare image and mask only\n",
        "  if predicted_breakdown is None and sample_masks is not None:\n",
        "    peek_images(sample_images=image1, sample_masks=mask, encode=encode, color_scale=color_scale, file_name=file_name, mask_name=mask_name, predict=predict, model=model)\n",
        "  # Compare original image and mask with predicted mask for model 1 or with model 1 and model 2\n",
        "  elif predicted_breakdown is not None and sample_masks is not None:\n",
        "    image1 = preprocessor_images(image1)\n",
        "    mask = preprocessor_images(mask)\n",
        "    if image2 is not None:\n",
        "      image2 = preprocessor_images(image2)\n",
        "    peek_images(sample_images=image1, sample_masks=mask, encode=encode, color_scale=color_scale, file_name=file_name, mask_name=mask_name, predict=predict, model=model, sample_images2=image2, model_alt=model_alt)\n",
        "    peek_masks_breakdown(sample_images=image1, sample_masks=mask, encode=encode, color_scale=color_scale, file_name=file_name, mask_name=mask_name, predict=predict, model=model)\n",
        "  # Test data, no masks\n",
        "  elif sample_masks is None:\n",
        "    image1 = preprocessor_images(image1)\n",
        "    peek_images_test(sample_images=image1, encode=encode, color_scale=color_scale, file_name=file_name, predict=predict, model=model)\n",
        "    # peek_masks_breakdown(sample_images=image, encode=encode, color_scale=color_scale, file_name=file_name, predict=predict, model=model)\n"
      ],
      "metadata": {
        "id": "hmzMNZYerLZq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell below multiple times to visually inspect random images and their associated masks as a sanity check."
      ],
      "metadata": {
        "id": "CqJj1oL7rXWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly selects image and mask from sample set and plot just to double check everything is working correctly.\n",
        "# Run this a few times to check on a few different image and mask sets\n",
        "sanity_check(abspath_curr + '/data/train/train_images/images/' , abspath_curr + '/data/train/train_masks/masks/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "mV1wFAmHrYfJ",
        "outputId": "aa8cb441-522d-4262-a48e-944b9777030d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-4fbca02d858e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Randomly selects image and mask from sample set and plot just to double check everything is working correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Run this a few times to check on a few different image and mask sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabspath_curr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/train/train_images/images/'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mabspath_curr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/train/train_masks/masks/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-e24aa73331a8>\u001b[0m in \u001b[0;36msanity_check\u001b[0;34m(sample_images, sample_masks, encode, color_scale, predict, model, model_alt, predicted_breakdown, imsize, imsize_alt)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mimage_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d, %d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0, 0, 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Set up generators, image preprocessing, and loading data to generators**"
      ],
      "metadata": {
        "id": "Ud1Hl7NJrjXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize(img, threshold=128):\n",
        "  \"\"\"\n",
        "  Function to binarize images at some threshold pixel value\n",
        "\n",
        "  Parameters:\n",
        "    img: image in numpy matrix\n",
        "    threshold: pixel threshold to binarize\n",
        "\n",
        "  Return:\n",
        "    img: binarized image in numpy matrix\n",
        "  \"\"\"\n",
        "  # Binarize the image\n",
        "  if np.max(img) > 1:\n",
        "    img[img > threshold] = 255\n",
        "    img[img <= threshold] = 0\n",
        "  else:\n",
        "    img[img > (threshold/255)] = 255\n",
        "    img[img <= (threshold/255)] = 0\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "N8ZQRcYgrmAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale(img):\n",
        "  \"\"\"\n",
        "  Function to rescale image from 0 to 255 to between 0 and 1.\n",
        "\n",
        "  Parameters:\n",
        "    img: image in numpy matrix\n",
        "\n",
        "  Return:\n",
        "    img: rescaled image in numpy matrix\n",
        "  \"\"\"\n",
        "  if np.max(img) > 1:\n",
        "    img = np.multiply(img, 1./255)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "ft7oSidkrpNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(img, class_map=None):\n",
        "  \"\"\"\n",
        "  Function to one hot encode ground truth masks\n",
        "\n",
        "  Parameters:\n",
        "    img: mask image where each channel represents a color channel\n",
        "    class_map: class_df\n",
        "\n",
        "  Return:\n",
        "    frame: one hot encoded image where each channel represents a class\n",
        "  \"\"\"\n",
        "\n",
        "  if class_map is None:\n",
        "    class_map = pd.DataFrame({'name':['urban_land','agriculture_land','rangeland','forest_land','water','barren_land','unknown'],\n",
        "                              'r':[0,255,255,0,0,255,0],\n",
        "                              'g':[255,255,0,255,0,255,0],\n",
        "                              'b':[255,0,255,0,255,255,0]})\n",
        "\n",
        "  img_copy = copy.deepcopy(img)\n",
        "  frame = np.zeros((img.shape[0], img.shape[1], len(class_map))).astype('int')\n",
        "\n",
        "  class_channel = 0\n",
        "\n",
        "  for index, row in class_df.iterrows():\n",
        "    new_img = copy.deepcopy(img_copy[::,::,::])\n",
        "\n",
        "    R = new_img[::,::,0]\n",
        "    G = new_img[::,::,1]\n",
        "    B = new_img[::,::,2]\n",
        "\n",
        "    # OHE each class type\n",
        "    new_img[(R == row['r']/255) & (G == row['g']/255) & (B == row['b']/255)] = 2\n",
        "    new_img[new_img < 2] = 0\n",
        "    new_img[new_img == 2] = 1\n",
        "\n",
        "    new_channel = copy.deepcopy(new_img[::,::,0])\n",
        "\n",
        "    # Take first layer since they are all the same and put into OHE mask\n",
        "    frame[::,::,class_channel] = new_channel\n",
        "\n",
        "    class_channel+=1\n",
        "\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "8UlG2lNWruZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_one_hot_encode(img, class_map=None):\n",
        "  \"\"\"\n",
        "  Function to reverse one hot encode 7 class channel to 3 channel RGB mask\n",
        "\n",
        "  Parameters:\n",
        "    img: image of one hot encoded mask image where each channel represents a class\n",
        "    class_map: class_df\n",
        "\n",
        "  Return:\n",
        "    rgb_img: reversed one hot encoded image of RGB channels\n",
        "  \"\"\"\n",
        "\n",
        "  if class_map is None:\n",
        "    class_map = pd.DataFrame({'name':['urban_land','agriculture_land','rangeland','forest_land','water','barren_land','unknown'],\n",
        "                              'r':[0,255,255,0,0,255,0],\n",
        "                              'g':[255,255,0,255,0,255,0],\n",
        "                              'b':[255,0,255,0,255,255,0]})\n",
        "\n",
        "  img = binarize(img)\n",
        "\n",
        "  all_red_channels = []\n",
        "  all_green_channels = []\n",
        "  all_blue_channels = []\n",
        "\n",
        "  class_channel = 0\n",
        "\n",
        "  for index, row in class_df.iterrows():\n",
        "\n",
        "    current_class_channel = copy.deepcopy(img[::,::,class_channel])\n",
        "\n",
        "    temp_rgb = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "\n",
        "    # if pixel value > 128 then put 0s in R, 255 in g, 255 in b\n",
        "    # or corresponding RGB for each class\n",
        "\n",
        "    if row['r'] > 0:\n",
        "      temp_rgb[::,::,0] = current_class_channel\n",
        "    if row['g'] > 0:\n",
        "      temp_rgb[::,::,1] = current_class_channel\n",
        "    if row['b'] > 0:\n",
        "      temp_rgb[::,::,2] = current_class_channel\n",
        "\n",
        "    all_red_channels.append(copy.deepcopy(temp_rgb[::,::,0]))\n",
        "    all_green_channels.append(copy.deepcopy(temp_rgb[::,::,1]))\n",
        "    all_blue_channels.append(copy.deepcopy(temp_rgb[::,::,2]))\n",
        "\n",
        "    class_channel += 1\n",
        "\n",
        "  red_stack = np.dstack(tuple(all_red_channels))\n",
        "  green_stack = np.dstack(tuple(all_green_channels))\n",
        "  blue_stack = np.dstack(tuple(all_blue_channels))\n",
        "\n",
        "  rgb_img = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "\n",
        "  rgb_img[::,::,0] = np.max(red_stack, axis=2)\n",
        "  rgb_img[::,::,1] = np.max(green_stack, axis=2)\n",
        "  rgb_img[::,::,2] = np.max(blue_stack, axis=2)\n",
        "\n",
        "  return rgb_img"
      ],
      "metadata": {
        "id": "0X0vx0jBrzFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessor_images(image, b_threshold=128):\n",
        "  \"\"\"\n",
        "  Function to combine preprocessing steps to feed into ImageDataGenerator.\n",
        "  'Masks' have to binarize then rescale. 'Images' just have to rescale.\n",
        "\n",
        "  Parameters:\n",
        "    image: image in numpy (x,y,3)\n",
        "    b_threshold: binary threshold value for pixels, default at 128.\n",
        "\n",
        "  Return:\n",
        "    final_img: final image to return from preprocessor after going through\n",
        "              all processing steps.\n",
        "  \"\"\"\n",
        "  final_img = rescale(image)\n",
        "\n",
        "  return final_img"
      ],
      "metadata": {
        "id": "8J18yx_Kr3w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessor_masks(image, b_threshold=128, class_map=None):\n",
        "  \"\"\"\n",
        "  Function to combine preprocessing steps to feed into ImageDataGenerator.\n",
        "  'Masks' have to binarize then rescale. 'Images' just have to rescale.\n",
        "\n",
        "  Parameters:\n",
        "    image: image in numpy (x,y,3)\n",
        "    class_map: mapping dataframe of classes and their corresponding RGB values for one hot encoding into separate channels\n",
        "    b_threshold: binary threshold value for pixels, default at 128.\n",
        "\n",
        "  Return:\n",
        "    final_img: final image to return from preprocessor after going through\n",
        "              all processing steps.\n",
        "  \"\"\"\n",
        "  image = one_hot_encode(image, class_map)\n",
        "  final_img = rescale(image)\n",
        "\n",
        "  return final_img"
      ],
      "metadata": {
        "id": "NTDgZHFLr6Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(img_folder, mask_folder, batch_size, imsize, num_classes, first_n=None):\n",
        "  \"\"\"\n",
        "  Function to create data generator object of images and masks.\n",
        "\n",
        "  Parameters:\n",
        "    img_folder: directory path to images folder\n",
        "    mask_folder: directory path to masks folder\n",
        "    batch_size: batch size to use\n",
        "    imsize: image height and width and n channels (image height, image width, n of channels)\n",
        "    first_n: optional, set to some int to choose only first n data points\n",
        "\n",
        "  Yields:\n",
        "    (img, mask): tuple of image and mask in np arrays of shape (batch size, image height, image width, n of channels)\n",
        "  \"\"\"\n",
        "  element_counter = 0\n",
        "\n",
        "  images_list = os.listdir(img_folder) #List of training images\n",
        "  masks_list = os.listdir(mask_folder) #List of Mask images\n",
        "\n",
        "  if first_n is None:\n",
        "    images_list = sorted(images_list)\n",
        "    masks_list= sorted(masks_list)\n",
        "  else:\n",
        "    images_list = sorted(images_list)[:first_n]\n",
        "    masks_list= sorted(masks_list)[:first_n]\n",
        "\n",
        "  while (True):\n",
        "    channel_num = 3\n",
        "    img = np.zeros((batch_size, imsize, imsize, channel_num)).astype('float')\n",
        "    mask = np.zeros((batch_size, imsize, imsize, num_classes)).astype('int')\n",
        "\n",
        "    for i in range(element_counter, element_counter+batch_size):\n",
        "\n",
        "      # Read an image from folder and resize\n",
        "      train_img = plt.imread(img_folder+'/'+images_list[i])\n",
        "      train_img =  cv2.resize(train_img, (imsize, imsize))\n",
        "\n",
        "      # Read corresponding mask from folder and resize\n",
        "      train_mask = plt.imread(mask_folder+'/'+masks_list[i])\n",
        "      train_mask = cv2.resize(train_mask, (imsize, imsize))\n",
        "\n",
        "      #Add pre-processing steps\n",
        "      train_img = preprocessor_images(train_img)\n",
        "      train_mask = preprocessor_masks(train_mask)\n",
        "\n",
        "      #add to array - img[0], img[1], and so on to created np framework\n",
        "      mask[i-element_counter] = train_mask\n",
        "      img[i-element_counter] = train_img\n",
        "\n",
        "    element_counter+=batch_size\n",
        "\n",
        "    # If we've reached the end of the batch, set element_counter back to 0 to start next batch\n",
        "    if(element_counter+batch_size>=len(images_list)):\n",
        "      element_counter=0\n",
        "\n",
        "    yield (img, mask)"
      ],
      "metadata": {
        "id": "e4RbvRiyr-ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**To modify**\n",
        "we can try diferent thinks Christina"
      ],
      "metadata": {
        "id": "vCCSKn2xrtwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model metadata parameters\n",
        "train_samples = 11568\n",
        "val_samples = 1280\n",
        "batch_size = 4\n",
        "num_classes = 7\n",
        "imsize = 612"
      ],
      "metadata": {
        "id": "KiYVVbHRsQTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generator objects for training and validation data for U-Net\n",
        "train_gen = data_generator(img_folder = abspath_curr + '/data/train/train_images/images/',\n",
        "                     mask_folder = abspath_curr + '/data/train/train_masks/masks/',\n",
        "                     batch_size = batch_size,\n",
        "                     imsize = imsize,\n",
        "                     num_classes = num_classes,\n",
        "                     first_n = train_samples)\n",
        "\n",
        "val_gen = data_generator(img_folder = abspath_curr + '/data/val/val_images/images/',\n",
        "                   mask_folder = abspath_curr + '/data/val/val_masks/masks/',\n",
        "                   batch_size = batch_size,\n",
        "                   imsize = imsize,\n",
        "                   num_classes = num_classes,\n",
        "                   first_n = val_samples)"
      ],
      "metadata": {
        "id": "-1qd2xKjsVIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generator objects for training and validation data for transfer learning\n",
        "transfer_learning_model_input_size = (512, 512, 3)\n",
        "\n",
        "train_gen_tl = data_generator(img_folder = abspath_curr + '/data/train/train_images/images/',\n",
        "                     mask_folder = abspath_curr + '/data/train/train_masks/masks/',\n",
        "                     batch_size = 1,\n",
        "                     imsize = transfer_learning_model_input_size[0],\n",
        "                     num_classes = num_classes,\n",
        "                     first_n = train_samples)\n",
        "\n",
        "val_gen_tl = data_generator(img_folder = abspath_curr + '/data/val/val_images/images/',\n",
        "                   mask_folder = abspath_curr + '/data/val/val_masks/masks/',\n",
        "                   batch_size = 1,\n",
        "                   imsize = transfer_learning_model_input_size[0],\n",
        "                   num_classes = num_classes,\n",
        "                   first_n = val_samples)"
      ],
      "metadata": {
        "id": "vyWoZ2u8sYLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build Model(s)**"
      ],
      "metadata": {
        "id": "_FwiBykOsduh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **U-Net Architecture**\n",
        "\n",
        "Important to note that I did not design this model from scratch. I took [sample boilerplate U-Net implementation](https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py) from the community and adjusted it to suit my needs.\n",
        "\n",
        "Optimizer:\n",
        "*   We will be using the [Adam optimization](https://keras.io/api/optimizers/adam/) which is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. This has shown to be a good optimizer to use for image segmentation problems by the machine learning community."
      ],
      "metadata": {
        "id": "P7WGjL2tshCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Implementation**"
      ],
      "metadata": {
        "id": "GdeU_1cftGCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make directory\n",
        "make_directory(abspath_curr + '/result/model/')"
      ],
      "metadata": {
        "id": "FpuwuWeGtKeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import keras and model specific objects\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input , Conv2D , MaxPooling2D , Dropout , concatenate , UpSampling2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation, MaxPool2D\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "nDeO3EW8tOwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_axis(x):\n",
        "  \"\"\"\n",
        "  Function to wrap Keras' Softmax activation function in order to deliver a value to the 'axis' parameter when defining model.\n",
        "\n",
        "  Parameters:\n",
        "    x: np array to perform Softmax on\n",
        "\n",
        "  Return:\n",
        "    softmax(x, axis=3): Ensures Softmax function is applied to the 3rd axis, depth along channels\n",
        "  \"\"\"\n",
        "  return softmax(x, axis=3)"
      ],
      "metadata": {
        "id": "w7cOhlxZtRYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_crop_shape(target, refer):\n",
        "  \"\"\"\n",
        "  Function to get new heights and widths to allow for cropping\n",
        "  and ensure proper size to allow for U-Net model concatenation between 2 outputs of Conv blocks.\n",
        "  This is part of the U-Net's skip connections.\n",
        "\n",
        "  Parameters:\n",
        "    target: target to crop\n",
        "    refer: reference for crop\n",
        "\n",
        "  Return:\n",
        "    (ch1, ch2), (cw1, cw2): heights and widths of new sizes to allow for proper cropping and concatenation.\n",
        "  \"\"\"\n",
        "  # width, the 3rd dimension\n",
        "  cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
        "  assert (cw >= 0)\n",
        "  if cw % 2 != 0:\n",
        "      cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
        "  else:\n",
        "      cw1, cw2 = int(cw/2), int(cw/2)\n",
        "\n",
        "  # height, the 2nd dimension\n",
        "  ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
        "  assert (ch >= 0)\n",
        "  if ch % 2 != 0:\n",
        "      ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
        "  else:\n",
        "      ch1, ch2 = int(ch/2), int(ch/2)\n",
        "\n",
        "  return (ch1, ch2), (cw1, cw2)"
      ],
      "metadata": {
        "id": "RZ7E45AztS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(pretrained_weights = None, input_size = (612,612,3), num_classes=7):\n",
        "  \"\"\"\n",
        "  Function to build U-Net network architecture.\n",
        "  See Figure 4 above for a visualization of the U-Net architecture.\n",
        "  Used https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py as template.\n",
        "\n",
        "  Parameters:\n",
        "    pretrained_weights: path to load pretrained weights if needed\n",
        "    input_size: (height, width, channels) size of input images\n",
        "    num_classes: number of channels/classes\n",
        "\n",
        "  Return:\n",
        "    model: Keras model of U-Net\n",
        "  \"\"\"\n",
        "  keras.backend.clear_session()\n",
        "  concat_axis = 3\n",
        "  inputs = layers.Input(shape = input_size)\n",
        "\n",
        "  conv1 = layers.Conv2D(64, (3, 3), padding='same', name='conv1_1')(inputs)\n",
        "  conv1 = layers.BatchNormalization()(conv1)\n",
        "  conv1 = layers.Activation('relu')(conv1)\n",
        "  conv1 = layers.Conv2D(64, (3, 3), padding='same')(conv1)\n",
        "  conv1 = layers.BatchNormalization()(conv1)\n",
        "  conv1 = layers.Activation('relu')(conv1)\n",
        "  pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  pool1 = layers.BatchNormalization()(pool1)\n",
        "\n",
        "  conv2 = layers.Conv2D(128, (3, 3), padding='same')(pool1)\n",
        "  conv2 = layers.BatchNormalization()(conv2)\n",
        "  conv2 = layers.Activation('relu')(conv2)\n",
        "  conv2 = layers.Conv2D(128, (3, 3), padding='same')(conv2)\n",
        "  conv2 = layers.BatchNormalization()(conv2)\n",
        "  conv2 = layers.Activation('relu')(conv2)\n",
        "  pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  pool2 = layers.BatchNormalization()(pool2)\n",
        "\n",
        "  conv3 = layers.Conv2D(256, (3, 3), padding='same')(pool2)\n",
        "  conv3 = layers.BatchNormalization()(conv3)\n",
        "  conv3 = layers.Activation('relu')(conv3)\n",
        "  conv3 = layers.Conv2D(256, (3, 3), padding='same')(conv3)\n",
        "  conv3 = layers.BatchNormalization()(conv3)\n",
        "  conv3 = layers.Activation('relu')(conv3)\n",
        "  pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  pool3 = layers.BatchNormalization()(pool3)\n",
        "\n",
        "  conv4 = layers.Conv2D(512, (3, 3), padding='same')(pool3)\n",
        "  conv4 = layers.BatchNormalization()(conv4)\n",
        "  conv4 = layers.Activation('relu')(conv4)\n",
        "  conv4 = layers.Conv2D(512, (3, 3), padding='same')(conv4)\n",
        "  conv4 = layers.BatchNormalization()(conv4)\n",
        "  conv4 = layers.Activation('relu')(conv4)\n",
        "  pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "  pool4 = layers.BatchNormalization()(pool4)\n",
        "\n",
        "  conv5 = layers.Conv2D(1024, (3, 3), padding='same')(pool4)\n",
        "  conv5 = layers.BatchNormalization()(conv5)\n",
        "  conv5 = layers.Activation('relu')(conv5)\n",
        "  conv5 = layers.Conv2D(1024, (3, 3), padding='same')(conv5)\n",
        "  conv5 = layers.BatchNormalization()(conv5)\n",
        "  conv5 = layers.Activation('relu')(conv5)\n",
        "\n",
        "  up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
        "  up_conv5 = layers.BatchNormalization()(up_conv5)\n",
        "  ch, cw = get_crop_shape(conv4, up_conv5)\n",
        "  crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
        "  up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
        "  conv6 = layers.Conv2D(512, (3, 3), padding='same')(up6)\n",
        "  conv6 = layers.BatchNormalization()(conv6)\n",
        "  conv6 = layers.Activation('relu')(conv6)\n",
        "  conv6 = layers.Conv2D(512, (3, 3), padding='same')(conv6)\n",
        "  conv6 = layers.BatchNormalization()(conv6)\n",
        "  conv6 = layers.Activation('relu')(conv6)\n",
        "\n",
        "  up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
        "  up_conv6 = layers.BatchNormalization()(up_conv6)\n",
        "  ch, cw = get_crop_shape(conv3, up_conv6)\n",
        "  crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
        "  up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis)\n",
        "  conv7 = layers.Conv2D(256, (3, 3), padding='same')(up7)\n",
        "  conv7 = layers.BatchNormalization()(conv7)\n",
        "  conv7 = layers.Activation('relu')(conv7)\n",
        "  conv7 = layers.Conv2D(256, (3, 3), padding='same')(conv7)\n",
        "  conv7 = layers.BatchNormalization()(conv7)\n",
        "  conv7 = layers.Activation('relu')(conv7)\n",
        "\n",
        "  up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
        "  up_conv7 = layers.BatchNormalization()(up_conv7)\n",
        "  ch, cw = get_crop_shape(conv2, up_conv7)\n",
        "  crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
        "  up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
        "  conv8 = layers.Conv2D(128, (3, 3), padding='same')(up8)\n",
        "  conv8 = layers.BatchNormalization()(conv8)\n",
        "  conv8 = layers.Activation('relu')(conv8)\n",
        "  conv8 = layers.Conv2D(128, (3, 3), padding='same')(conv8)\n",
        "  conv8 = layers.BatchNormalization()(conv8)\n",
        "  conv8 = layers.Activation('relu')(conv8)\n",
        "\n",
        "  up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
        "  up_conv8 = layers.BatchNormalization()(up_conv8)\n",
        "  ch, cw = get_crop_shape(conv1, up_conv8)\n",
        "  crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
        "  up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
        "  conv9 = layers.Conv2D(64, (3, 3), padding='same')(up9)\n",
        "  conv9 = layers.BatchNormalization()(conv9)\n",
        "  conv9 = layers.Activation('relu')(conv9)\n",
        "  conv9 = layers.Conv2D(64, (3, 3), padding='same')(conv9)\n",
        "  conv9 = layers.BatchNormalization()(conv9)\n",
        "  conv9 = layers.Activation('relu')(conv9)\n",
        "\n",
        "  ch, cw = get_crop_shape(inputs, conv9)\n",
        "  conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
        "\n",
        "  outputs = layers.Conv2D(num_classes, (1, 1), activation=softmax_axis,  padding='same')(conv9)\n",
        "\n",
        "  model = models.Model(inputs=inputs, outputs=outputs, name='U-Net')\n",
        "\n",
        "  if(pretrained_weights):\n",
        "    model.load_weights(pretrained_weights)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "tQJnZ_CDtWRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Function to calculate Dice Coefficient\n",
        "\n",
        "    Parameters:\n",
        "      y_true: True label\n",
        "      y_pred: Predicted label\n",
        "      smooth: Apply a smoothness hyperparameter value\n",
        "\n",
        "    Return:\n",
        "      Dice Coefficient\n",
        "\n",
        "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
        "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
        "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Function to return 1-Dice Coeff as the loss\n",
        "\n",
        "    Parameters:\n",
        "      y_true: True label\n",
        "      y_pred: Predicted label\n",
        "\n",
        "    Return:\n",
        "      Dice Coefficient Loss\n",
        "    \"\"\"\n",
        "    return 1-dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "A1FGzHCqtZny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt at using class weighted pixel-wise cross entropy but did not yield good convergence and therefore results\n",
        "weights = class_pixels['True Weights'].tolist()\n",
        "\n",
        "def weighted_pixelwise_crossentropy(class_weights):\n",
        "\n",
        "  def loss(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "    # epsilon = _to_tensor(_EPSILON, y_pred.dtype.base_dtype)\n",
        "    epsilon = K.epsilon()\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "    return - tf.reduce_sum(tf.math.multiply(y_true * tf.math.log(y_pred), class_weights))\n",
        "\n",
        "  return loss\n",
        "\n",
        "loss = weighted_pixelwise_crossentropy(weights)"
      ],
      "metadata": {
        "id": "var4t6Q1tcHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained model\n",
        "model = unet(pretrained_weights = abspath_curr + '/result/model/unet_model_v3_epoch6.h5', input_size = (imsize,imsize,3), num_classes = num_classes)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr = 1e-5)\n",
        "model.compile(optimizer=opt, loss=dice_coef_loss, metrics=[dice_coef, tf.keras.metrics.MeanIoU(num_classes=num_classes), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l3Un8ZZpteFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=abspath_curr + '/result/model/transfer_learning_modelv3_epoch18_21.h5',\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only=True)\n",
        "\n",
        "# EarlyStopping callback\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=4,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "# ReduceLROnPlateau callback\n",
        "reduce_lr_on_plateau_cb = keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.1,\n",
        "    patience=3)"
      ],
      "metadata": {
        "id": "Yli6q_9MtkaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Training**"
      ],
      "metadata": {
        "id": "Jrw-e1aUtngp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_gen,\n",
        "                    epochs = 10,\n",
        "                    initial_epoch = 6,\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    validation_data = val_gen,\n",
        "                    validation_steps = val_samples//batch_size,\n",
        "                    verbose=1,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint_cb, early_stopping_cb, reduce_lr_on_plateau_cb]\n",
        "                    )"
      ],
      "metadata": {
        "id": "_XAjURUEtpZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Transfer Learning**"
      ],
      "metadata": {
        "id": "brgXLMG_tw4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input, num_filters):\n",
        "  '''\n",
        "  A convolutional block\n",
        "  '''\n",
        "  x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "  '''\n",
        "  A decoder block\n",
        "  '''\n",
        "  x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "  x = Concatenate()([x, skip_features])\n",
        "  x = conv_block(x, num_filters)\n",
        "  return x\n",
        "\n",
        "def build_resnet50_unet(input_shape, freeze_all_layers=False, fine_tune_at=None, pretrained_weights = None):\n",
        "  '''\n",
        "  Build a U-Net architecture using ResNet50 as the backbone pretrained on ImageNet\n",
        "  '''\n",
        "  keras.backend.clear_session()\n",
        "  # Input\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  # Pre-trained ResNet50 Model\n",
        "  resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "  # Encoder\n",
        "  s1 = resnet50.get_layer(index=0).output           ## (512 x 512)\n",
        "  s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n",
        "  s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n",
        "  s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n",
        "\n",
        "  # Bridge\n",
        "  b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n",
        "\n",
        "  # Decoder\n",
        "  d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "  d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "  d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "  d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "  # Output\n",
        "  outputs = keras.layers.Conv2D(num_classes, (1, 1), activation=softmax_axis,  padding='same')(d4)\n",
        "\n",
        "  model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n",
        "\n",
        "  if(pretrained_weights):\n",
        "    model.load_weights(pretrained_weights)\n",
        "\n",
        "  if freeze_all_layers:\n",
        "    # For each layer in the pretrained model\n",
        "    for layer in resnet50.layers:\n",
        "      # Freeze the layer\n",
        "      layer.trainable = False\n",
        "  else:\n",
        "    # For each layer in the pretrained model\n",
        "    for layer in resnet50.layers:\n",
        "      # Freeze the layer\n",
        "      layer.trainable = True\n",
        "\n",
        "  if fine_tune_at is not None:\n",
        "    # For each layer in the pretrained model\n",
        "    for layer in resnet50.layers[fine_tune_at:]:\n",
        "        # Unfreeze the layer\n",
        "        layer.trainable = True\n",
        "\n",
        "  return model, resnet50\n"
      ],
      "metadata": {
        "id": "fPejVq9RtzKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2, pretrained_model = build_resnet50_unet(pretrained_weights = abspath_curr + '/result/model/transfer_learning_modelv3_epoch8_18.h5', input_shape = transfer_learning_model_input_size, freeze_all_layers=False)\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "3tkKXZEQt5PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(lr = 1e-5)\n",
        "\n",
        "model2.compile(\n",
        "  optimizer=opt,\n",
        "  loss=dice_coef_loss,\n",
        "  metrics=[dice_coef, tf.keras.metrics.MeanIoU(num_classes=num_classes), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
      ],
      "metadata": {
        "id": "oGej2JeGt7cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(train_gen_tl,\n",
        "                    epochs = 21,\n",
        "                    initial_epoch = 18,\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    validation_data = val_gen_tl,\n",
        "                    validation_steps = val_samples//batch_size,\n",
        "                    verbose=1,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint_cb, early_stopping_cb, reduce_lr_on_plateau_cb])\n",
        "\n",
        "\n",
        "make_directory(abspath_curr + '/result/figure/')\n",
        "history_df = pd.DataFrame(history2.history)\n",
        "history_df.to_csv(abspath_curr + '/result/figure/history_transferlearningmodelv3_ep18_21.csv', index=False)"
      ],
      "metadata": {
        "id": "jlYhl7EFt91C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation Results**"
      ],
      "metadata": {
        "id": "yHdL80wvuDWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "read_from_csv = True\n",
        "history_file = abspath_curr + '/result/figure/history_transferlearningmodelv3.csv'\n",
        "\n",
        "make_directory(abspath_curr + '/result/figure/')\n",
        "\n",
        "# Load history_df, concat to history\n",
        "if read_from_csv:\n",
        "  history_df_loaded = pd.read_csv(history_file)\n",
        "  # history_df_loaded2 = pd.read_csv(history_file2)\n",
        "  history_df = history_df_loaded.copy()\n",
        "  # history_df2 = history_df_loaded2.copy()\n",
        "  # history_df = pd.concat([history_df_loaded, history_df_loaded2], axis=0)\n",
        "  # history_df.reset_index(drop=True, inplace=True)\n",
        "else:\n",
        "  history_df = pd.DataFrame(history.history)\n",
        "  history_df\n",
        "\n",
        "# Create a figure\n",
        "# Save and show the figure\n",
        "fig, axs = plt.subplots(5, figsize=(8,24))\n",
        "\n",
        "axs[0].plot(history_df.index + 1, history_df['loss'], label='Training Dice Loss')\n",
        "axs[0].plot(history_df.index + 1, history_df['val_loss'], label='Val. Dice Loss')\n",
        "axs[0].legend(loc=\"upper right\")\n",
        "axs[0].set_title('Loss')\n",
        "axs[0].set_xlabel('End of Epoch')\n",
        "\n",
        "axs[1].plot(history_df.index + 1, history_df['dice_coef'], label='Pixelwise Dice Coef.')\n",
        "axs[1].plot(history_df.index + 1, history_df['val_dice_coef'], label='Val. Pixelwise Dice Coef.')\n",
        "axs[1].legend(loc=\"upper right\")\n",
        "axs[1].set_title('Dice Coefficient')\n",
        "axs[1].set_xlabel('End of Epoch')\n",
        "\n",
        "axs[2].plot(history_df.index + 1, history_df['recall'], label='Pixelwise Recall')\n",
        "axs[2].plot(history_df.index + 1, history_df['val_recall'], label='Val. Pixelwise Recall')\n",
        "axs[2].legend(loc=\"upper right\")\n",
        "axs[2].set_title('Recall')\n",
        "axs[2].set_xlabel('End of Epoch')\n",
        "\n",
        "axs[3].plot(history_df.index + 1, history_df['precision'], label='Pixelwise Precision')\n",
        "axs[3].plot(history_df.index + 1, history_df['val_precision'], label='Val. Pixelwise Precision')\n",
        "axs[3].legend(loc=\"upper right\")\n",
        "axs[3].set_title('Precision')\n",
        "axs[3].set_xlabel('End of Epoch')\n",
        "\n",
        "axs[4].plot(history_df.index + 1, history_df['lr'], label='Learning Rate')\n",
        "axs[4].legend(loc=\"upper right\")\n",
        "axs[4].set_title('Learning Rate')\n",
        "axs[4].set_xlabel('End of Epoch')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(abspath_curr + '/result/figure/learning_curve_model_v3.pdf')\n",
        "\n",
        "history_df.to_csv(abspath_curr + '/result/figure/history_data_model_v3.csv', index=False)\n",
        "# print(history_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2JaWw_30uCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **U-Net Only Architecture Validation Results**"
      ],
      "metadata": {
        "id": "ZUApBaLcuSt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select validation image and mask then predict and plot prediction.\n",
        "# Run this a few times to check on a few different image and mask sets\n",
        "sanity_check(abspath_curr + '/data/val/val_images/images/' , abspath_curr + '/data/val/val_masks/masks/', predict=True, model=model, predicted_breakdown=True)"
      ],
      "metadata": {
        "id": "k0EN5FgxuWay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ResNet50_U-Net Architecture Results**"
      ],
      "metadata": {
        "id": "08gjDi9IufWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select validation image and mask then predict and plot prediction.\n",
        "# Run this a few times to check on a few different image and mask sets\n",
        "sanity_check(abspath_curr + '/data/val/val_images/images/' , abspath_curr + '/data/val/val_masks/masks/', predict=True, model=model2, model_alt=model, predicted_breakdown=True, imsize=transfer_learning_model_input_size[0], imsize_alt=imsize)"
      ],
      "metadata": {
        "id": "iDC_rIUuucy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Data**"
      ],
      "metadata": {
        "id": "DdK7pspjuo4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ResNet50_U-Net Architecture Test Results**\n"
      ],
      "metadata": {
        "id": "cnQfrN0IurFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select test image then predict and plot prediction.\n",
        "# Run this a few times to check on a few different image and prediction sets.\n",
        "sanity_check(abspath_curr + '/data/test/', predict=True, model=model2, predicted_breakdown=False, imsize=transfer_learning_model_input_size[0])"
      ],
      "metadata": {
        "id": "roM02tNduwiS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}